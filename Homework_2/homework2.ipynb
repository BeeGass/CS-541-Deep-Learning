{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from pdb import set_trace"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(x, y):\n",
    "    X_t = x.T\n",
    "    X_y = X_t.dot(y) # x is a column vector so it needs to be transformed\n",
    "    X_XT = X_t.dot(x)\n",
    "    w = np.linalg.solve(X_XT, X_y) #(X_XT dot X_y)^-1\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, w, b):\n",
    "    y_hat = x.dot(w) + b\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square_error(y_hat, y):\n",
    "    n = y.shape[0]\n",
    "    mse = (1/(2 * n)) * np.sum(np.square(y_hat - y))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2(w, y, alpha = 0.01):\n",
    "    n = y.shape[0]\n",
    "    wt_w = (w).dot(w.T) # (w^T)w\n",
    "    reg = (1/(2 * n) * alpha) * wt_w # (alpha/2n) * ((w^T)w) \n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularized_mean_square_error(y, y_hat, reg):\n",
    "    n = y.shape[0]\n",
    "    mse = mean_square_error(y_hat, y)\n",
    "    return mse + reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train/Test Split performed by randomly taking inputs and their associated labels and assigning them to either a training group or a test group\n",
    "#---------------------------------------------------#----------------#\n",
    "#                                                   |                |\n",
    "#                  Training set                     |   Testing Set  |\n",
    "#                                                   |                |\n",
    "#---------------------------------------------------#----------------#\n",
    "#train_perc should be a value between 0 and 1, eg. train_perc 0.8\n",
    "def random_train_test_split(dataset, train_perc = 0.8):\n",
    "    perc_of_dataset = dataset.shape[1] * train_perc\n",
    "    numpy.random.shuffle(dataset)\n",
    "\n",
    "    train = dataset_arrx[:perc_of_dataset,:] \n",
    "    test = dataset_arr[perc_of_dataset:,:]\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation/Test Split performed by randomly taking inputs and their associated labels and assigning them to either a validation group or a test group\n",
    "#---------------------------------------------------#----------------#\n",
    "#                                                   |                |\n",
    "#                  Training set                     |   Testing Set  |\n",
    "#                                                   |                |\n",
    "#---------------------------------------------------#----------------#\n",
    "#                                                             V\n",
    "#                                                |------------#---------#\n",
    "#                                                |            |         |\n",
    "#                                                | Validation | Testing |\n",
    "#                                                |     Set    |   Set   |\n",
    "#                                                |------------#---------#\n",
    "#train_perc should be a value between 0 and 1, eg. train_perc 0.5 for a 50/50 split of the test set \n",
    "def random_test_validation_split(x, y, train_perc = 0.8):\n",
    "    dataset_row_size, dataset_col_size = x.shape\n",
    "    validation_set_size = int(dataset_row_size * train_perc)\n",
    "    test_set_size = int(dataset_row_size - validation_set_size)\n",
    "\n",
    "    #get random indices for both validation and test sets\n",
    "    indices = np.random.permutation(x.shape[0])\n",
    "    validation_p_index = indices[:validation_set_size]\n",
    "    test_p_index = indices[test_set_size:]\n",
    "\n",
    "    #validation and test labels\n",
    "    validation_l = y[validation_p_index]\n",
    "    test_l = y[test_p_index]\n",
    "\n",
    "    #validation and test parameters \n",
    "    validation_p = x[validation_p_index]\n",
    "    test_p = x[test_p_index]\n",
    "\n",
    "    return validation_p, validation_l, test_p, test_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X is the input \n",
    "#y is the real result\n",
    "#w is the weight \n",
    "#epsilon is the learning rate\n",
    "#alpha is the regularized term\n",
    "#reg_bool if you wish to use the regularized term\n",
    "def gradient_descent(x, y, b, w, learning_rate, reg_bool):\n",
    "    # batch_size x 2304\n",
    "    X_t = x.T # 2304 x batch_size\n",
    "    n = y.shape[0]\n",
    "    y_hat = model(x, w, b)\n",
    "\n",
    "    #taking derivative \n",
    "    # 2304 x 1 \n",
    "    derivative_of_w = (1/n) * X_t.dot(y_hat - y)\n",
    "    derivative_of_b = (1/n) * (y_hat - y)\n",
    "\n",
    "    # if regularized term is wanted then add that to the derivative with respect to w\n",
    "    if reg_bool == True:\n",
    "        derivative_of_w += ((alpha/n) * w)\n",
    "\n",
    "    #this is gradient descent\n",
    "    w = w - (learning_rate * derivative_of_w)\n",
    "    b = b - (learning_rate * derivative_of_b)\n",
    "\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ripped from https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(b))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_that_beh(history: dict):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history[\"epoch\"], history[\"cost\"], 'g', label='loss over epoch')\n",
    "    plt.title('cost to epoch ')\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history[\"epoch\"], history[\"learning_rate\"], 'b', label='learning rate over epoch')\n",
    "    plt.title('learning rate to epoch')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iterator(x, y, size_of_batch):\n",
    "    assert (len(x) == len(y))\n",
    "    p = np.random.permutation(x.shape[0])\n",
    "    x_rand = x[p]\n",
    "    y_rand = y[p]\n",
    "    for i in np.arange(0, x.shape[0], size_of_batch):\n",
    "        yield x_rand[i:i + size_of_batch], y_rand[i:i + size_of_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(x, y, b, w, learning_rate: float, num_of_epochs: int, size_of_batch: int, size_of_dataset: int, reg_bool: bool = True):\n",
    "    set_trace()\n",
    "    past_cost = 1e1000\n",
    "    current_cost = -1\n",
    "    history = {\n",
    "        \"epoch\": -1,\n",
    "        \"weight\": -1,\n",
    "        \"bias\": -1,\n",
    "        \"cost\": -1,\n",
    "        \"batch_size\": math.ceil(size_of_dataset/size_of_batch),\n",
    "        \"learning rate\": -1\n",
    "    }\n",
    "\n",
    "    epochs_since_improved = 0\n",
    "\n",
    "    for e in range(num_of_epochs - 1):\n",
    "        shuffled_x, shuffled_y = unison_shuffled_copies(x, y)\n",
    "\n",
    "        for mini_batch_x, mini_batch_y in batch_iterator(x, y, size_of_batch):\n",
    "            y_hat = model(mini_batch_x, w, b)\n",
    "\n",
    "            if reg_bool == True:\n",
    "                reg = l2(w, mini_batch_y)\n",
    "                current_cost = regularized_mean_square_error(mini_batch_y, y_hat, reg)\n",
    "            else:\n",
    "                current_cost = mean_square_error(y_hat, mini_batch_y)\n",
    "\n",
    "            \n",
    "            w, b = gradient_descent(mini_batch_x, mini_batch_y, b, w, learning_rate, reg_bool)\n",
    "\n",
    "            print(\"MSE: \", current_cost)\n",
    "            print(\"Past MSE: \", past_cost)\n",
    "\n",
    "        if (past_cost < current_cost): # if past cost remains to be lower than current cost, increment counter\n",
    "            epoch_since_improved += 1\n",
    "\n",
    "            if epoch_since_improved >= 3:\n",
    "                learning_rate /= 10 #learning rate decays if cost does not lower after 3 epochs \n",
    "                print(\"learning rate decayed\")\n",
    "                print(\"epochs since improved: \", epoch_since_improved)\n",
    "                \n",
    "        else: # if current cost is lower than past cost set the counter to zero and update the past cost value\n",
    "            epoch_since_improved = 0 \n",
    "            past_cost = current_cost\n",
    "            print(\"current cost is lower\")\n",
    "\n",
    "        history[\"epoch\"] += 1\n",
    "        history[\"weight\"] = w\n",
    "        history[\"bias\"] = b\n",
    "        history[\"cost\"] = current_cost\n",
    "        history[\"learning_rate\"] = learning_rate\n",
    "\n",
    "    visualize_that_beh(history)\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lowest_loss(x, y, learning_rate, num_of_epochs, size_of_batch, reg_bool = True):\n",
    "    size_of_dataset = len(y)\n",
    "    l = np.expand_dims(a=y, axis=-1)\n",
    "    w_shape = (x.shape[1], l.shape[1]) #2304 x 1\n",
    "    w = np.random.rand(*w_shape) * np.sqrt(1/(x.shape[1] + l.shape[1])) #set intial w value based off Xavier intilization\n",
    "    b = np.random.rand(l.shape[1]) #set initial bias value \n",
    "    reg = l2(w, y) # set regularized term\n",
    "    w_new, b_new = stochastic_gradient_descent(x, y, b, w, learning_rate, num_of_epochs, size_of_batch, size_of_dataset, reg_bool)\n",
    "    loss = train_valid_test(x, w, b, y, reg, reg_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_test(x, w, b, y, reg: float, reg_bool: bool = False):\n",
    "    y_hat = model(x, w, b)\n",
    "    if reg_bool:\n",
    "        train_or_validation = regularized_mean_square_error(y, y_hat, reg)\n",
    "        test = regularized_mean_square_error(y, y_hat, reg)\n",
    "    else:\n",
    "        train_or_validation = mean_square_error(y_hat, y)\n",
    "        test = mean_square_error(y_hat, y)\n",
    "\n",
    "    return train_or_validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    #training set\n",
    "    x_tr = np.reshape(np.load(\"age_regression_Xtr.npy\"), (-1, 48*48))\n",
    "    y_tr = np.load(\"age_regression_ytr.npy\")\n",
    "\n",
    "    #testing set\n",
    "    x_te = np.reshape(np.load(\"age_regression_Xte.npy\"), (-1, 48*48))\n",
    "    y_te = np.load(\"age_regression_yte.npy\")\n",
    "\n",
    "    return x_tr, y_tr, x_te, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function Arguments:\n",
    "#mse_bool is the boolean value that determines if mse will be performed without or with regularization, default is True\n",
    "#alpha is the value for regularization, if used, default is 0.0\n",
    "#ttv_val is the value associated with the type of split wanted. A Train/Test Split is 0, and a train/validation/split is 1, No Split Needed is 2. Default is 2\n",
    "#learning rate is the hyperparameter associated with the gradient descent\n",
    "def train_age_regressor(num_of_epochs: int, size_of_batch: int, ttv_val: int = 2, the_set: int = 0, learning_rate: float = 0.1, reg_bool = False):\n",
    "    # Load data\n",
    "    x_tr, y_tr, x_te, y_te = load_data()\n",
    "\n",
    "    if ttv_val == 0:\n",
    "        print(\"I made this before I realized train/test split is already given to you\")\n",
    "\n",
    "    elif ttv_val == 1:\n",
    "        x_val, y_val, x_te, y_te = random_test_validation_split(x_te, y_te, train_perc = 0.8)\n",
    "\n",
    "    loss = 1000000000\n",
    "    if the_set == 0: #training set\n",
    "        loss = find_lowest_loss(x_tr, y_tr, learning_rate, num_of_epochs, size_of_batch, reg_bool)\n",
    "    elif the_set == 1: #validation set\n",
    "        loss = find_lowest_loss(x_val, y_val, learning_rate, num_of_epochs, size_of_batch, reg_bool)\n",
    "    elif the_set == 2: #test set\n",
    "        loss = find_lowest_loss(x_te, y_te, learning_rate, num_of_epochs, size_of_batch, reg_bool)\n",
    "    else:\n",
    "        print(\"you did something wrong bud\")\n",
    "\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> \u001b[1;32m<ipython-input-13-419320dd4a20>\u001b[0m(3)\u001b[0;36mstochastic_gradient_descent\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      1 \u001b[1;33m\u001b[1;32mdef\u001b[0m \u001b[0mstochastic_gradient_descent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_of_epochs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_of_batch\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_of_dataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_bool\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      2 \u001b[1;33m    \u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m----> 3 \u001b[1;33m    \u001b[0mpast_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      4 \u001b[1;33m    \u001b[0mcurrent_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      5 \u001b[1;33m    history = {\n",
      "\u001b[0m\n",
      "> \u001b[1;32m<ipython-input-13-419320dd4a20>\u001b[0m(4)\u001b[0;36mstochastic_gradient_descent\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      2 \u001b[1;33m    \u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      3 \u001b[1;33m    \u001b[0mpast_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m----> 4 \u001b[1;33m    \u001b[0mcurrent_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      5 \u001b[1;33m    history = {\n",
      "\u001b[0m\u001b[1;32m      6 \u001b[1;33m        \u001b[1;34m\"epoch\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[1;32m<ipython-input-13-419320dd4a20>\u001b[0m(6)\u001b[0;36mstochastic_gradient_descent\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      4 \u001b[1;33m    \u001b[0mcurrent_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      5 \u001b[1;33m    history = {\n",
      "\u001b[0m\u001b[1;32m----> 6 \u001b[1;33m        \u001b[1;34m\"epoch\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      7 \u001b[1;33m        \u001b[1;34m\"weight\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      8 \u001b[1;33m        \u001b[1;34m\"bias\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[1;32m<ipython-input-13-419320dd4a20>\u001b[0m(7)\u001b[0;36mstochastic_gradient_descent\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      5 \u001b[1;33m    history = {\n",
      "\u001b[0m\u001b[1;32m      6 \u001b[1;33m        \u001b[1;34m\"epoch\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m----> 7 \u001b[1;33m        \u001b[1;34m\"weight\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      8 \u001b[1;33m        \u001b[1;34m\"bias\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      9 \u001b[1;33m        \u001b[1;34m\"cost\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[1;32m<ipython-input-13-419320dd4a20>\u001b[0m(8)\u001b[0;36mstochastic_gradient_descent\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      6 \u001b[1;33m        \u001b[1;34m\"epoch\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      7 \u001b[1;33m        \u001b[1;34m\"weight\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m----> 8 \u001b[1;33m        \u001b[1;34m\"bias\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      9 \u001b[1;33m        \u001b[1;34m\"cost\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     10 \u001b[1;33m        \u001b[1;34m\"batch_size\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_of_dataset\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msize_of_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[1;32m<ipython-input-13-419320dd4a20>\u001b[0m(9)\u001b[0;36mstochastic_gradient_descent\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      7 \u001b[1;33m        \u001b[1;34m\"weight\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      8 \u001b[1;33m        \u001b[1;34m\"bias\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m----> 9 \u001b[1;33m        \u001b[1;34m\"cost\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     10 \u001b[1;33m        \u001b[1;34m\"batch_size\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_of_dataset\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msize_of_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     11 \u001b[1;33m        \u001b[1;34m\"learning rate\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[1;32m<ipython-input-13-419320dd4a20>\u001b[0m(10)\u001b[0;36mstochastic_gradient_descent\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      8 \u001b[1;33m        \u001b[1;34m\"bias\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      9 \u001b[1;33m        \u001b[1;34m\"cost\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 10 \u001b[1;33m        \u001b[1;34m\"batch_size\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_of_dataset\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msize_of_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     11 \u001b[1;33m        \u001b[1;34m\"learning rate\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     12 \u001b[1;33m    }\n",
      "\u001b[0m\n",
      "> \u001b[1;32m<ipython-input-13-419320dd4a20>\u001b[0m(11)\u001b[0;36mstochastic_gradient_descent\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      9 \u001b[1;33m        \u001b[1;34m\"cost\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     10 \u001b[1;33m        \u001b[1;34m\"batch_size\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_of_dataset\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msize_of_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 11 \u001b[1;33m        \u001b[1;34m\"learning rate\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     12 \u001b[1;33m    }\n",
      "\u001b[0m\u001b[1;32m     13 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[1;32m<ipython-input-13-419320dd4a20>\u001b[0m(5)\u001b[0;36mstochastic_gradient_descent\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      3 \u001b[1;33m    \u001b[0mpast_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      4 \u001b[1;33m    \u001b[0mcurrent_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m----> 5 \u001b[1;33m    history = {\n",
      "\u001b[0m\u001b[1;32m      6 \u001b[1;33m        \u001b[1;34m\"epoch\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      7 \u001b[1;33m        \u001b[1;34m\"weight\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "*** NameError: name 'nn' is not defined\n",
      "> \u001b[1;32m<ipython-input-13-419320dd4a20>\u001b[0m(14)\u001b[0;36mstochastic_gradient_descent\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     12 \u001b[1;33m    }\n",
      "\u001b[0m\u001b[1;32m     13 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 14 \u001b[1;33m    \u001b[0mepochs_since_improved\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     15 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     16 \u001b[1;33m    \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_of_epochs\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[1;32m<ipython-input-13-419320dd4a20>\u001b[0m(16)\u001b[0;36mstochastic_gradient_descent\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     14 \u001b[1;33m    \u001b[0mepochs_since_improved\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     15 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 16 \u001b[1;33m    \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_of_epochs\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     17 \u001b[1;33m        \u001b[0mshuffled_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffled_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munison_shuffled_copies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     18 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[1;32m<ipython-input-13-419320dd4a20>\u001b[0m(17)\u001b[0;36mstochastic_gradient_descent\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     15 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     16 \u001b[1;33m    \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_of_epochs\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 17 \u001b[1;33m        \u001b[0mshuffled_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffled_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munison_shuffled_copies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     18 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     19 \u001b[1;33m        \u001b[1;32mfor\u001b[0m \u001b[0mmini_batch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_y\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_of_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[1;32m<ipython-input-13-419320dd4a20>\u001b[0m(19)\u001b[0;36mstochastic_gradient_descent\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     17 \u001b[1;33m        \u001b[0mshuffled_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffled_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munison_shuffled_copies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     18 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 19 \u001b[1;33m        \u001b[1;32mfor\u001b[0m \u001b[0mmini_batch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_y\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_of_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     20 \u001b[1;33m            \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini_batch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     21 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "BdbQuit",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-3f43040c0337>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_age_regressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_of_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_of_batch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mttv_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_bool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-db26861c6b72>\u001b[0m in \u001b[0;36mtrain_age_regressor\u001b[1;34m(num_of_epochs, size_of_batch, ttv_val, the_set, learning_rate, reg_bool)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000000000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mthe_set\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_lowest_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_of_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_of_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_bool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mthe_set\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#validation set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_lowest_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_of_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_of_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_bool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-9310b6240c59>\u001b[0m in \u001b[0;36mfind_lowest_loss\u001b[1;34m(x, y, learning_rate, num_of_epochs, size_of_batch, reg_bool)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#set initial bias value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# set regularized term\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mw_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstochastic_gradient_descent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_of_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_of_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_of_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_bool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_valid_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_bool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-419320dd4a20>\u001b[0m in \u001b[0;36mstochastic_gradient_descent\u001b[1;34m(x, y, b, w, learning_rate, num_of_epochs, size_of_batch, size_of_dataset, reg_bool)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mshuffled_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffled_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munison_shuffled_copies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mmini_batch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_y\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_of_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini_batch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-419320dd4a20>\u001b[0m in \u001b[0;36mstochastic_gradient_descent\u001b[1;34m(x, y, b, w, learning_rate, num_of_epochs, size_of_batch, size_of_dataset, reg_bool)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mshuffled_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffled_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munison_shuffled_copies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mmini_batch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_y\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_of_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini_batch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;31m# None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'line'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'call'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(train_age_regressor(num_of_epochs=300, size_of_batch=100, ttv_val=1, the_set=0, learning_rate=0.001, reg_bool=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}