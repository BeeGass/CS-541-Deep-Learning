{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[9, 10]\n[1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "arr = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "print(arr[8:])\n",
    "print(arr[:8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression (x, y):\n",
    "    X_t = x.T\n",
    "    X_y = X_t.dot(y) # x is a column vector so it needs to be transformed\n",
    "    X_XT = X_t.dot(x)\n",
    "    w = np.linalg.solve(X_XT, X_y)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square_error(y, x, w, b):\n",
    "    n = len(y)\n",
    "    mean_div_two = 1/(2 * n)\n",
    "    y_hat = x.dot(w) + b\n",
    "    euclid_dist = np.sum(np.square(y_hat-y))\n",
    "    err = mean_div_two * euclid_dist\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularized_mean_square_error(y, x, w, b, alpha):\n",
    "    n = len(y)\n",
    "    div_two_n = 1/(2 * n) # 1/2n\n",
    "    y_hat = x.dot(w) + b  # y_hat = xw + b\n",
    "    euclid_dist = np.sum(np.square(y_hat-y))  # sum of (y_hat - y)^2\n",
    "    err = div_two_n * euclid_dist # (1/2n) * (sum of (y_hat - y)^2)\n",
    "    wt_w = (w).dot(w.T) # (w^T)w\n",
    "    reg = (div_two_n * alpha) * wt_w # (alpha/2n) * ((w^T)w) \n",
    "    return err + reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train/Test Split performed by randomly taking inputs and their associated labels and assigning them to either a training group or a test group\n",
    "#---------------------------------------------------#----------------#\n",
    "#                                                   |                |\n",
    "#                  Training set                     |   Testing Set  |\n",
    "#                                                   |                |\n",
    "#---------------------------------------------------#----------------#\n",
    "#train_perc should be a value between 0 and 1, eg. train_perc 0.8\n",
    "def random_train_test_split(dataset, train_perc = 0.8):\n",
    "    perc_of_dataset = dataset.shape[1] * train_perc\n",
    "    numpy.random.shuffle(dataset)\n",
    "\n",
    "    train = dataset_arrx[:perc_of_dataset,:] \n",
    "    test = dataset_arr[perc_of_dataset:,:]\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation/Test Split performed by randomly taking inputs and their associated labels and assigning them to either a validation group or a test group\n",
    "#---------------------------------------------------#----------------#\n",
    "#                                                   |                |\n",
    "#                  Training set                     |   Testing Set  |\n",
    "#                                                   |                |\n",
    "#---------------------------------------------------#----------------#\n",
    "#                                                             V\n",
    "#                                                |------------#---------#\n",
    "#                                                |            |         |\n",
    "#                                                | Validation | Testing |\n",
    "#                                                |     Set    |   Set   |\n",
    "#                                                |------------#---------#\n",
    "#train_perc should be a value between 0 and 1, eg. train_perc 0.5 for a 50/50 split of the test set \n",
    "def random_test_validation_split(parameter, labels, train_perc = 0.8):\n",
    "    dataset_row_size, dataset_col_size = dataset.shape\n",
    "    validation_set_size = dataset_row_size * train_perc\n",
    "    test_set_size = dataset_row_size - validation_set_size\n",
    "\n",
    "    indices = numpy.random.permutation(parameter.shape[0])\n",
    "    validation_p_index = indices[:validation_set_size]\n",
    "    test_p_index = indices[test_set_size:]\n",
    "\n",
    "    validation_l, test_l = labels[validation_p_idx,:], labels[test_p_idx,:]\n",
    "    validation_p, test_p = parameter[validation_p_idx,:], parameter[test_p_idx,:]\n",
    "\n",
    "    return validation_p, validation_l, test_p, test_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(learning_rate: float, num_of_epochs: int, alpha: float):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    #training set\n",
    "    x_tr = np.reshape(np.load(\"age_regression_Xtr.npy\"), (-1, 48*48))\n",
    "    y_tr = np.load(\"age_regression_ytr.npy\")\n",
    "\n",
    "    #testing set\n",
    "    x_te = np.reshape(np.load(\"age_regression_Xte.npy\"), (-1, 48*48))\n",
    "    y_te = np.load(\"age_regression_yte.npy\")\n",
    "\n",
    "    return x_tr, y_tr, x_te, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'boolean' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8137202c264b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_age_regressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmse_bool\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_val\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mttv_bool\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mboolean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;31m# Load data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mX_tr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"age_regression_Xtr.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m48\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mytr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"age_regression_ytr.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mX_te\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"age_regression_Xte.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m48\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'boolean' is not defined"
     ]
    }
   ],
   "source": [
    "#Function Arguments:\n",
    "#mse_bool is the boolean value that determines if mse will be performed without or with regularization, default is True\n",
    "#alpha is the value for regularization, if used, default is 0.0\n",
    "#ttv_val is the value associated with the type of split wanted. A Train/Test Split is 0, and a train/validation/split is 1, No Split Needed is 2. Default is 2\n",
    "#learning rate is the hyperparameter associated with the gradient descent\n",
    "def train_age_regressor(mse_bool: bool = True, alpha: float = 0.0, ttv_val: int = 2, learning_rate: float, num_of_epochs: int):\n",
    "    # Load data\n",
    "    x_tr, y_tr, x_te, y_te = load_data()\n",
    "\n",
    "    if ttv_val == 0:\n",
    "        print(\"I made this before I realized train/test split is already given to you\")\n",
    "\n",
    "    elif ttv_val == 1:\n",
    "        x_val, y_val, x_te, y_te = random_test_validation_split(x_te, y_te, train_perc = 0.8)\n",
    "\n",
    "    w = linear_regression(X_tr, ytr)\n",
    "\n",
    "    #set initial bias value \n",
    "    np.zeros((w.shape))\n",
    "\n",
    "    if mse_bool == True:\n",
    "        train = mean_square_error(ytr, X_tr, w, b_val)\n",
    "        test = mean_square_error(yte, X_te, w, b_val)\n",
    "    else:\n",
    "        train = regularized_mean_square_error(ytr, X_tr, w, b_val, alpha)\n",
    "        test = regularized_mean_square_error(yte, X_te, w, b_val, alpha)\n",
    "\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "    # Report fMSE cost on the training and testing data (separately)\n",
    "    # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(94.98633435331956, 358.60415394117115)\n"
     ]
    }
   ],
   "source": [
    "print(train_age_regressor(mse_bool=False, b_val=2, alpha=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}