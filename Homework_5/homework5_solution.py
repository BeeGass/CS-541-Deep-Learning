# -*- coding: utf-8 -*-
"""CS541Homework5

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a6cSIfXuuY9A5u9MNNPFz376vBRrDn5N
"""

# Note in Colab you can type "pip install" directly in the notebook
#!pip install -q -U tensorflow>=1.8.0
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
# Load the fashion-mnist pre-shuffled train data and test data
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()

x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

# Further break training data into train / validation sets (# put 5000 into validation set and keep remaining 55,000 for train)
(x_train, x_valid) = x_train[5000:], x_train[:5000] 
(y_train, y_valid) = y_train[5000:], y_train[:5000]

# Reshape input data from (28, 28) to (28, 28, 1)
w, h = 28, 28
x_train = x_train.reshape(x_train.shape[0], w, h, 1)
x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)
x_test = x_test.reshape(x_test.shape[0], w, h, 1)

# One-hot encode the labels
y_train = tf.keras.utils.to_categorical(y_train, 10)
y_valid = tf.keras.utils.to_categorical(y_valid, 10)
y_test = tf.keras.utils.to_categorical(y_test, 10)

model = tf.keras.Sequential()
# Must define the input shape in the first layer of the neural network
model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='valid', input_shape=(28,28,1))) 
model.add(tf.keras.layers.MaxPooling2D(pool_size=2, padding='valid'))
model.add(tf.keras.layers.ReLU())
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(1024, activation='relu'))
model.add(tf.keras.layers.Dense(10, activation='softmax'))


model.compile(loss='categorical_crossentropy',
             optimizer='adam',
             metrics=['accuracy'])

model.fit(x_train,
         y_train,
         batch_size=64,
         epochs=1,
         validation_data=(x_valid, y_valid))

# Evaluate the model on test set
score = model.evaluate(x_test, y_test, verbose=0)
# Print test accuracy
print('\n', 'Test accuracy:', score[1])

def convertWeights (model):
        idx = 0
        W1 = np.zeros((64*26*26, 28*28))
        b1 = np.zeros((64*26*26,))
        convKernels = model.trainable_variables[0].numpy()
        convBiases = model.trainable_variables[1].numpy()
        W2 = model.trainable_variables[2].numpy().T
        b2 = model.trainable_variables[3].numpy()
        W3 = model.trainable_variables[4].numpy().T
        b3 = model.trainable_variables[5].numpy()
        idx = 0
        
        for i in range(26):  # 2 less than 28 due to "valid" convolution region
                for j in range(26):  # 2 less than 28 due to "valid" convolution region
                      for f in range(64):  # Crucial to iterate this in inner-most loop, due to how TensorFlow packs the filters
                                for row in range(3):
                                        startIdx = (i + row)*28 + j
                                        endIdx = startIdx + 3
                                        W1[idx, startIdx:endIdx] = convKernels[row,:,0,f]
                                        b1[idx] = convBiases[f]
                                idx += 1
        return W1, b1, W2, b2, W3, b3

def fc (W, b, x):
        return W.dot(x) + b

def mp (x):
        h = np.zeros((13, 13, 64))
        x = x.reshape((26, 26, 64))
        for i in range(0, 26-1, 2):
                for j in range(0, 26-1, 2):
                          for f in range(64):
                                someX = x[i:i+2, j:j+2, f]
                                h[i//2, j//2, f] = np.max(someX)
        return h.flatten()

def softmax (x):
        x = np.exp(x)
        return x / np.sum(x, axis=0)

def relu (x):
        return np.maximum(0, x)

W1, b1, W2, b2, W3, b3 = convertWeights(model)

x = x_train[0,:,:,0].flatten()
yhat = softmax(fc(W3, b3, relu(fc(W2, b2, relu(mp(fc(W1, b1, x)))))))
print(yhat)
print(model.predict(x_train[0:1,:,:,:])[0])
